#### 1 (TSDB Results) ####-----------------------------------------------------------------------------------------------

a. How many items parsed?
    -Initial (5.1): Testsuite-, Corpus-
    -Final (5.2): Testsuite-, Corpus-

b. What was the average number of parses?
    -Initial: Testsuite-, Corpus-
    -Final: Testsuite-, Corpus-

c. How many parses did the most ambiguous item receive?
    -Initial: Testsuite-, Corpus-
    -Final: Testsuite-, Corpus-

d. What sources of ambiguity can you identify?

e. For 4 newly parsing or otherwise fixed items (2 in the testsuite, 2 in the corpus), do any of the parses look reasonable in the semantics?

#### 2 (Documentation of MMT Translation) ####---------------------------------------------------------------------------
This week we added translations for several different phenomena, though we weren't able to get each one working in our grammar. First of all, we added translations for Wh-questions, as seen in Examples 23 and 24:

#EXAMPLE 23
Source: author
Vetted: f
Judgment: g
Phenomena: {Matrix wh questions}
yaq=ḥaˑ weʔič
who=INTERR.3 sleep
Who sleeps?

#EXAMPLE 24
Source: author
Vetted: f
Judgment: g
Phenomena: {Matrix wh questions}
qʷi=ḥaˑ casšiƛ ʕiniiƛ
what=ITERR.3 chase dog
What do the dogs chase?

As can be seen, the Wh-words are found sentence-initially and take an affix indicating the interrogative mood as well as the agreement information for the Subject of the clause. This may be somewhat confusing for sentences in which the the Subject is being questioned, but it can be regarded as solely grammatical agreement with the "who" pronoun, not necessarily indicating that the questioned person need be 3rd-Person. This happens in English too: "Who unleash[es] the cats? -> You unleash[] the cats".

Wh-relative clauses work using a very parallel structure, but with different words. This can be seen in the following examples from David Inman, the first being a lone wh-relative clause and the second being the embedded wh-question from the MT sentences:

yaqʷ=qiˑtq casšiƛ ʕiniiƛ
that.which=DEF chase dog
"what the dog(s) chase"

#EXAMPLE 18
Source: d
Vetted: f
Judgment: g
Phenomena: {Agreement, Embedded-Wh-Ques}
ʔaʔaatu=mit=maˑḥ yaqʷ=yii casšiƛ ʕiniiƛ
ask=past=INDIC.1sg that.which=INDEF.3 chase dog
I asked what dogs chased

We were advised to steer clear of this early on in the week, because according to Emily, the fact that the embedded question is identical to the relative clause and not the corresponding Wh-question is not easily ammenable to the matrix grammar as it stands. Thus, our Example 18 is translated, but not covered.


Next we added possession:

#EXAMPLE 20
Source: author
Vetted: f
Judgment: g
Phenomena: {Possesive}
weʔič=maˑ ʕiniiƛ=uk=(m)aˑḥ
sleep=INDIC.3 dog=POSS=1sg
My dogs sleep

We had already implemented a possession strategy in an earlier week: marked on possessum, possessor can be dropped. The suffix =uk was correctly adding the POSS information but =(m)aˑḥ was supposed to be contributing the PNG of the possessor and this was not working correctly. According to Elizabeth Nielsen, any lexical rule from her library that is contributing features to the possessor need to be part of the rule that adds the POSS feature. We attempted to find a work-around to add the possessor PNG later but were unsucessful. Instead, we simply made a compound suffix '=uk=(m)aˑḥ' that adds both featuers in a single rule. This would get unwieldy to do for all PNG but is within the scope of the adnominal possession library which was already implemented which keeps things reasonable for this course.  


#### 3 (Documentation of Added Phenomena) ####---------------------------------------------------------------------------

## Wh-Questions (Unsuccessful) ##

We began to develop an implementation for Wh-questions as seen in the previous section, but ran into trouble with the fact that this seems to be a second-position phenomenon that is hard to work around. We borrowed the wh-ques-phrase, extracted-subj-phrase, extracted-comp-phrase, and wh-prounoun-noun-lex types from the given English grammar. However, the wh-ques-phrase expects that the wh-word acts as a noun "filler" to the gappy clause, whereas our current analysis of agreement clitics in Nuuchahnulth regard them as affixes on the sentence-initial verb. Thus, our wh-words are incompatible with the gap-filler type, or more specifically, the wh-pronoun types are not compatible with what we analyze as the initial verb morphology.

## Modal Auxiliaries ##

The phenomenon we were able to add successfully was modal auxiliaries, specifically adding Example 27 to our coverage:

#EXAMPLE 27 -- ʔink actually means "fire"
Source: author
Vetted: f
Judgment: g
Phenomena: {modals}
ʔuʔumḥi=maˑḥ haʔuk ʔink
can=INDIC.1sg eat glass
I can eat glass

To do this, we used a subject-raising auxiliary type similar to the one we used for negation and added the needed form to our lexicon:

subj-raise-aux := aux-lex & trans-first-arg-raising-lex-item &
  [ SYNSEM.LOCAL [ CAT.VAL [ SPR < >,
                             SPEC < >,
                             COMPS < #comps >,
                             SUBJ < #subj > ],
                   CONT.HOOK.XARG #xarg ],
    ARG-ST < #subj &
             [ LOCAL [ CAT [ HEAD noun,
                             VAL [ SUBJ < >,
                                   SPR < >,
                                   SPEC < >,
                                   COMPS < > ] ],
                       CONT.HOOK.INDEX #xarg ] ],
             #comps &
             [ OPT -,
	       LOCAL.CAT [ VAL [ SUBJ < unexpressed >,
                                 COMPS < >,
                                 SPR < >,
                                 SPEC < > ],
                           HEAD verb ] ] > ].

subj-raise-aux-with-pred := subj-raise-aux & norm-sem-lex-item & trans-first-arg-raising-lex-item-1.

modal-aux-lex := subj-raise-aux-with-pred & (verb-pc-dtrs...) &
  [ SYNSEM.LOCAL.CAT.VAL.COMPS.FIRST.LOCAL.CAT.HEAD.FORM nonfinite,
    INFLECTED [ VERB-TENSE-FLAG - ] ].

neg-aux-lex := subj-raise-aux-with-pred & (verb-pc-dtrs...) &
  [ SYNSEM.LOCAL.CAT.VAL.COMPS.FIRST.LOCAL.CAT.HEAD.FORM nonfinite,
    INFLECTED [ VERB-TENSE-FLAG - ] ].

We also improved upon the structure for both this and the neg-aux-lex, because before we did not account for the fact that the complement of an auxiliary verb must not have any of the mood/agreement clitics that appear on the main verb (second position clitics). For example, both of the following would be ungrammatical, and are correctly ruled out by our grammar:

ʔuʔumḥi haʔuk=maˑḥ ʔink
can eat=INDIC.1sg glass
intended: *'I can eat glass'

wik haʔuk=maˑḥ ʔink
neg eat=INDIC.1sg glass
intended: *'I do not eat glass'

To accomplish this, we made sure that both the modal-aux-lex and neg-aux-lex (above) require their complements to be FORM nonfinite, and also that the second-position-clitics specify FORM finite on the verbs they attach to, as follows:

verb-pc161-lex-rule-super := add-only-no-ccont-rule & infl-lex-rule &
  [ SYNSEM.LOCAL.CAT.HEAD.FORM finite,
    INFLECTED #infl & [ CLITIC-CLUSTER-FLAG + ],
    DTR verb-pc15-or-verb-pc161-rule-dtr &
        [ INFLECTED #infl ] ].

#### 4 (Documentation of LKB Generation) ####---------------------------------------------------------------------------- We have had geneartion working for the last two weeks but the number of generated sentences is incredilby high. Last week we began using only the irules that had features to reduce the count but even then there were too many generated to be useful. This week, we began looking into other ways to reduce the number of generated sentences.

After examining the output of nuk to nuk generation, we realized that the leading culprit was underspcified features. Namely, if tense, person, or number were not specified in the input, all possible combinations of those suffixes appeared in the generated output leading to a combinatorial explosion.

First, we looked to improve the handling of tense. We realized that we had only implemented past tense 'pst' and were leaving all others as unspecified. This meant any present tense was also generatig a pst version. The default without specific

#### 5 (Documentation of Machine Translation Setup) ####-----------------------------------------------------------------
