#### 1 (TSDB Results) ####-----------------------------------------------------------------------------------------------

a. How many items parsed?
    -Initial (5.2): Testsuite-59, Corpus-33
    -Final:  Testsuite- , Corpus-

b. What was the average number of parses?
    -Initial: Testsuite-1.76, Corpus-2.12
    -Final:  Testsuite- , Corpus-

c. How many parses did the most ambiguous item receive?
    -Initial: Testsuite-6, Corpus-6
    -Final:  Testsuite- , Corpus-
d. What sources of ambiguity can you identify?

#### 2 (MRS Refinement) ####-----------------------------------------------------------------------------------------------
1. The first change we did was to unify the name on our locative verbs so that both versions used the the '_be+located_v_rel' as we settled on in class. Next, we implemented the transfer rule to change '_in_p_rel' to our rel:

in-to-be-located := monotonic_mtr & 
[ INPUT [ RELS < [ PRED "_in_p_rel",
  LBL #lbl,
  ARG0 #arg0,
  ARG1 #arg1,
  ARG2 #arg2 ] >,
      HCONS < > ],
  OUTPUT [ RELS < [ PRED "_be+located_v_rel",
   LBL #lbl,
   ARG0 #arg0,
   ARG1 #arg1,
   ARG2 #arg2 ] > ]].

This allowed us to translate the following:

MMT 13
haʔuk=maˑ ʕiniiƛ hił čaačist
eat=INDIC.3 dog in park
Dogs in the park eat

MMT 16
hił=maˑ ʕiniiƛ čaačist
at=INDIC.3 dog park
The dogs are in the park

2. We were unable to translate the 3rd sentence (or any with pronouns) to start:
MMT 3
eng
I chase you
1sg.pron chase.1st 2nd.pron
I chase you

nuk
casšiƛ=maˑḥ suw̓a
chase=INDIC.1sg 2nd.pron
I chase you 


First, we added optional pronoun dropping since the subject and object can be dropped:

pronoun-delete-mtr := monotonic_omtr &
 [ INPUT [ RELS < [ PRED "pron_rel",
		     ARG0 #x,
		     LBL #larg ],
		 [ PRED "exist_q_rel",
		   ARG0 #x,
		   RSTR #harg ] >,
	   HCONS < qeq & [ LARG #larg,
			    HARG #harg ] > ],
   OUTPUT [ RELS < >,
	    HCONS < > ]].

 This allowed us to generate 'casšiƛ=maˑḥ' which is allowed. However, we still weren't getting the desired version that included 'suw̓a'. We looked at the lexical entry for 'suw̓a' and realized that it had been generated with a non-matching predicate so we changed it from '_you_n_rel' to 'pron_rel'. Then we looked in 'nuuchahnulth.tdl' and saw it was inheriting from a noun type that had 3rd person features. We fixed this inheritence so that 'suw̓a' is now correctly 2nd person.

#### 3 (Overgeneration Changes) ####-----------------------------------------------------------------------------------------------

The first major change we made to prevent overgeneration was pruning our Irules set to only the affixes used in the testsuite and mmt sentences that also model semantics of some sort. This reduced some of our coverage in the testsuite, since some of our non-constructed examples contained morphemes for which we do not yet model semantics. Secondly, we amended the vpm rules to prevent under specified Mood, Aspect, and Tense values from overgenerating when translating to Nuuchahnulth.

    E.TENSE : TENSE
      pst <> past
      pres <> present
      pres << [e]
      pres << *

    E.ASPECT : ASPECT
      cont >> cont
      dur >> dur
      temp >> temp
      perf >> perf
      * >> no-aspect
      perf << perf
      no-aspect << [e]
      no-aspect << *

    E.MOOD : MOOD
      indic <> indic
      cond <> cond
      quot <> quot
      dub <> dub
      abs <> abs
      subord <> subord
      interr <> interr
      indic << [e]
      indic << *

For Aspect, we decided to constrain our vpm rules to export all values identically, but only import Perfective, and change everything else to no-aspect. This is because Pite Saami seems to have some form of Aspect, and our grammar can generate Perfective Aspect accurately at least. For Mood, we allow any of our supported Moods to be imported or exported. However, anything else is imported as Indicative, as "basic" Nuuchahnulth sentences have Indicative Mood. Similarly, for Tense we allow Present or Past to be imported, but otherwise set the Tense to Present, as basic Nuuchahnulth sentences are interpreted as Present, and we generate this accurately through an lrule.

For Mood, event though we had set up semi.vpm correctly to map underspecified to Indicative Mood, our grammar was still generating non-indicative versions of the sentences. E.g. both of the following were generated from 'Dogs sleep':
Weʔič ʕiniiƛ
sleep dog
weʔič=maˑ ʕiniiƛ
sleep=INDIC.3 dog

After working with Emily during office hours, we realized this was because the Mood position class was not obligatory so the underspecified versions were still compatible with the internal MRS generated from the semi.vpm. We made the Mood position class obligatory on all its inputs which correctly ruled out the non-mood inflected generation.

#### 4 (Ambiguity Explanation) ####------------------------------------------------------------------------------------------------

## Word Order ##
As discussed in previous labs, when both Subject and Object are present in a Nuuchahnulth clause, they can appear in either order after the Verb. This is one of our main sources of (warranted) ambiguity when translating to Nuuchahnulth. In cases like Example #9 where there are two clauses with Subject and Object, four different sentences (2^2) are generated just from this freedom of word order.

    #9 -- "Dogs chase cars and cats chase dogs"
    #chase=INDIC.3 dog car and chase=INDIC.3 cat dog (first order)
    Casšiƛ=maˑ ʕiniiƛ huupuk̓ʷas ʔaḥʔaaʔaƛ casšiƛ=maˑ piišpiš ʕiniiƛ
    Casšiƛ=maˑ ʕiniiƛ huupuk̓ʷas ʔaḥʔaaʔaƛ casšiƛ=maˑ ʕiniiƛ piišpiš
    Casšiƛ=maˑ huupuk̓ʷas ʕiniiƛ ʔaḥʔaaʔaƛ casšiƛ=maˑ piišpiš ʕiniiƛ
    Casšiƛ=maˑ huupuk̓ʷas ʕiniiƛ ʔaḥʔaaʔaƛ casšiƛ=maˑ ʕiniiƛ piišpiš




#### 5 (MMT Coverage) ####---------------------------------------------------------------------------------------------------------
eng
1: covered
2: covered
3: coverd
4: covered
5: covered
6: nuk skipped
7: nuk skipped
8: covered
9: covered
10: covered
11: covered
12: nuk skipped
13: covered
14: nuk skipped
15: nuk skipped
16: covered
17: covered
18: nuk skipped
19: nuk skipped
20: covered
21: covered
22: nuk skipped
23: wh- out of scope for nuk
24: wh- out of scope for nuk
25: nuk skipped
26: nuk skipped
27: nuk skipped
28: nuk skipped

sje
1: covered
2: covered
3: covered
4: covered
5: covered
6: nuk skipped 
7: nuk skipped 
8: covered
9: covered
10: covered
11: covered
12: nuk skipped
13 sje not coverd
14: nuk skipped
15: nuk skipped
16 sje skipped
17 sje skipped
18: nuk skipped
19: nuk skipped
20: covered
21 sje skipped
22: nuk skipped
23:: wh- out of scope for nuk
24: wh- out of scope for nuk
25: nuk skipped
26: nuk skipped
27: nuk skipped
28: nuk skipped
