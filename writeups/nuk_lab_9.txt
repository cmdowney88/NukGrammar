#### 1 (TSDB Results) ####-----------------------------------------------------------------------------------------------

a. How many items parsed?
    -Initial (5.2): Testsuite-59, Corpus-33
    -Final:  Testsuite-34 , Corpus-2.2 -- with reduced irules.tdl

b. What was the average number of parses?
    -Initial: Testsuite-1.76, Corpus-2.12
    -Final:  Testsuite-1.53 , Corpus-1.5-- with reduced irules.tdl

c. How many parses did the most ambiguous item receive?
    -Initial: Testsuite-6, Corpus-6
    -Final:  Testsuite-4 , Corpus-2

d. What sources of ambiguity can you identify?
There are no new sources of ambiguity. The 4 readings are for the subject/object ambiguity inherient to Nuuchahnulth combined with two lexical entries with the same spelling after creating missing words for the MMT. 

#### 2 (MRS Refinement) ####-----------------------------------------------------------------------------------------------
1. The first change we did was to unify the name on our locative verbs so that both versions used the the '_be+located_v_rel' as we settled on in class. Next, we implemented the transfer rule to change '_in_p_rel' to our rel:

in-to-be-located := monotonic_mtr & 
[ INPUT [ RELS < [ PRED "_in_p_rel",
  LBL #lbl,
  ARG0 #arg0,
  ARG1 #arg1,
  ARG2 #arg2 ] >,
      HCONS < > ],
  OUTPUT [ RELS < [ PRED "_be+located_v_rel",
   LBL #lbl,
   ARG0 #arg0,
   ARG1 #arg1,
   ARG2 #arg2 ] > ]].

This allowed us to translate the following:

MMT 13
haʔuk=maˑ ʕiniiƛ hił čaačist
eat=INDIC.3 dog in park
Dogs in the park eat

MMT 16
hił=maˑ ʕiniiƛ čaačist
at=INDIC.3 dog park
The dogs are in the park

2. We were unable to translate the 3rd sentence (or any with pronouns) to start:
MMT 3
eng
I chase you
1sg.pron chase.1st 2nd.pron
I chase you

nuk
casšiƛ=maˑḥ suw̓a
chase=INDIC.1sg 2nd.pron
I chase you 


First, we added optional pronoun dropping since the subject and object can be dropped:

pronoun-delete-mtr := monotonic_omtr &
 [ INPUT [ RELS < [ PRED "pron_rel",
		     ARG0 #x,
		     LBL #larg ],
		 [ PRED "exist_q_rel",
		   ARG0 #x,
		   RSTR #harg ] >,
	   HCONS < qeq & [ LARG #larg,
			    HARG #harg ] > ],
   OUTPUT [ RELS < >,
	    HCONS < > ]].

 This allowed us to generate 'casšiƛ=maˑḥ' which is allowed. However, we still weren't getting the desired version that included 'suw̓a'. We looked at the lexical entry for 'suw̓a' and realized that it had been generated with a non-matching predicate so we changed it from '_you_n_rel' to 'pron_rel'. Then we looked in 'nuuchahnulth.tdl' and saw it was inheriting from a noun type that had 3rd person features. We fixed this inheritence so that 'suw̓a' is now correctly 2nd person.

#### 3 (Overgeneration Changes) ####-----------------------------------------------------------------------------------------------

The first major change we made to prevent overgeneration was pruning our Irules set to only the affixes used in the testsuite and mmt sentences that also model semantics of some sort. This reduced some of our coverage in the testsuite, since some of our non-constructed examples contained morphemes for which we do not yet model semantics. Secondly, we amended the vpm rules to prevent under specified Mood, Aspect, and Tense values from overgenerating when translating to Nuuchahnulth.

    E.TENSE : TENSE
      pst <> past
      pres <> present
      pres << [e]
      pres << *

    E.ASPECT : ASPECT
      cont >> cont
      dur >> dur
      temp >> temp
      perf >> perf
      * >> no-aspect
      perf << perf
      no-aspect << [e]
      no-aspect << *

    E.MOOD : MOOD
      indic <> indic
      cond <> cond
      quot <> quot
      dub <> dub
      abs <> abs
      subord <> subord
      interr <> interr
      indic << [e]
      indic << *

For Aspect, we decided to constrain our vpm rules to export all values identically, but only import Perfective, and change everything else to no-aspect. This is because Pite Saami seems to have some form of Aspect, and our grammar can generate Perfective Aspect accurately at least. For Mood, we allow any of our supported Moods to be imported or exported. However, anything else is imported as Indicative, as "basic" Nuuchahnulth sentences have Indicative Mood. Similarly, for Tense we allow Present or Past to be imported, but otherwise set the Tense to Present, as basic Nuuchahnulth sentences are interpreted as Present, and we generate this accurately through an lrule.

For Mood, event though we had set up semi.vpm correctly to map underspecified to Indicative Mood, our grammar was still generating non-indicative versions of the sentences. E.g. both of the following were generated from 'Dogs sleep':

    Weʔič ʕiniiƛ
    sleep dog
    weʔič=maˑ ʕiniiƛ
    sleep=INDIC.3 dog

After working with Emily during office hours, we realized this was because the Mood position class was not obligatory so the underspecified versions were still compatible with the internal MRS generated from the semi.vpm. We made the Mood position class obligatory on all its inputs which correctly ruled out the non-mood inflected generation. In adddition to this, we had to modify our rules for Coordination. This is because being a top-level S requires that that the head be FORM finite, but S's that are coordinated  had no such restriction, even though these must have Mood in Nuuchahnulth. Thus we added the following type addenda:

    s-coord-phrase :+ [ LCOORD-DTR.SYNSEM.LOCAL.CAT.HEAD.FORM finite,
                        RCOORD-DTR.SYNSEM.LOCAL.CAT.HEAD.FORM finite ].

    s-bottom-coord-phrase :+ [ NONCONJ-DTR.SYNSEM.LOCAL.CAT.HEAD.FORM finite ].

    vp-coord-phrase :+ [ LCOORD-DTR.SYNSEM.LOCAL.CAT.HEAD.FORM finite ].

    vp-bottom-coord-phrase :+ [ NONCONJ-DTR.SYNSEM.LOCAL.CAT.HEAD.FORM nonfinite ].

In contrast to coordinated sentences, the second coordinated VP must not receive Mood inflection, thus we specify that the bottom VP have FORM nonfinite.


#### 4 (Ambiguity Explanation) ####------------------------------------------------------------------------------------------------
## Word Order ##
As discussed in previous labs, when both Subject and Object are present in a Nuuchahnulth clause, they can appear in either order after the Verb. This is one of our main sources of (warranted) ambiguity when translating to Nuuchahnulth. In cases like Example #9 where there are two clauses with Subject and Object, four different sentences (2^2) are generated just from this freedom of word order.

    #9 -- "Dogs chase cars and cats chase dogs"
    #chase=INDIC.3 dog car and chase=INDIC.3 cat dog (first order)
    Casšiƛ=maˑ ʕiniiƛ huupuk̓ʷas ʔaḥʔaaʔaƛ casšiƛ=maˑ piišpiš ʕiniiƛ
    Casšiƛ=maˑ ʕiniiƛ huupuk̓ʷas ʔaḥʔaaʔaƛ casšiƛ=maˑ ʕiniiƛ piišpiš
    Casšiƛ=maˑ huupuk̓ʷas ʕiniiƛ ʔaḥʔaaʔaƛ casšiƛ=maˑ piišpiš ʕiniiƛ
    Casšiƛ=maˑ huupuk̓ʷas ʕiniiƛ ʔaḥʔaaʔaƛ casšiƛ=maˑ ʕiniiƛ piišpiš

## Spelling ##
We also see ambiguity from different spellings of the affixes. For example the following 3 1sg.Indic suffixes are all present in our corpus: (m)aˑḥ, =maˑḥ, =aˑḥ. We could unify our irules further to just the first version but haven't yet in order to keep coverage decent and account for the variety of spellings.

## Pronoun Dropping ##
Pronomial objects can be dropped in Nuuchahnulth. For example, 'ʔuʔiis' is transitive 'eat' while 'haʔuk' is the intrasitive version. Since objects can be dropped, this allows the intransitive 'dogs eat' to be traslated as both

    Haʔuk=maˑ ʕiniiƛ
    eat(intras)=3rd.Indic dog

    ʔuʔiis=maˑ ʕiniiƛ
    eat(trans)=3rd.Indic dog

This is always going to happen because the contextual dropping of objects has to be supported so both of these Nuuchahnulth examples are grammatical. 

## Direction of "because" Relation ##
One source of ambiguity we weren't able to solve was that for Example 21 "the dog sleeps because the cat sleeps", our translations are generating sentences with the reverse semantics. Our translation generates the following:

    Weʔič=maˑ ʕiniiƛ ʔani weʔič=maˑ piišpiš
    sleep=INDIC.3 dog because sleep=INDIC.3 cat
    Weʔič=maˑ ʔani weʔič=maˑ piišpiš ʕiniiƛ
    sleep=INDIC.3 because sleep=INDIC.3 cat dog
    "The dog sleeps because the cat sleeps"

    Weʔič=maˑ piišpiš ʔani weʔič=maˑ ʕiniiƛ
    sleep=INDIC.3 cat because sleep=INDIC.3 dog
    Weʔič=maˑ ʔani weʔič=maˑ ʕiniiƛ piišpiš
    sleep=INDIC.3 because sleep=INDIC.3 dog cat
    "The cat sleeps because the dog sleeps"

As can be seen, the first two generated sentences align with the semantics of the English sentence from which the translation comes, whereas the second two have the opposite semantics. We confirmed that this second set of semantics was different (opposite) from the target with Emily on Canvas, and were advised to document it but not try to pursue the problem further.

#### 5 (MMT Coverage) ####---------------------------------------------------------------------------------------------------------
eng
1: covered
2: covered
3: coverd
4: covered
5: covered
6: nuk skipped
7: nuk skipped
8: covered
9: covered
10: covered
11: covered
12: nuk skipped
13: covered
14: nuk skipped
15: nuk skipped
16: covered
17: covered
18: nuk skipped
19: nuk skipped
20: covered
21: covered
22: nuk skipped
23: wh- out of scope for nuk
24: wh- out of scope for nuk
25: nuk skipped
26: nuk skipped
27: nuk skipped
28: nuk skipped

sje
1: covered
2: covered
3: covered
4: covered
5: covered
6: nuk skipped 
7: nuk skipped 
8: covered
9: covered
10: covered
11: covered
12: nuk skipped
13 sje not covered
14: nuk skipped
15: nuk skipped
16 sje skipped
17 sje skipped
18: nuk skipped
19: nuk skipped
20: covered
21 sje skipped
22: nuk skipped
23:: wh- out of scope for nuk
24: wh- out of scope for nuk
25: nuk skipped
26: nuk skipped
27: nuk skipped
28: nuk skipped
